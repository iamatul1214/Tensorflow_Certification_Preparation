{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamatul1214/Tensorflow_Certification_Preparation/blob/main/05_TransferLearning_using_tensorflow_part2_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MaoulC9J1qc"
      },
      "source": [
        "### Here we will perform transfer learning with fine tuning of our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T5TIrBWJiyI",
        "outputId": "8ca92e87-2103-48bd-a4ed-74759f877bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Tensorflow certifications work\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "Root = \"/content/drive/MyDrive/Tensorflow certifications work\"\n",
        "!pwd\n",
        "os.chdir(Root)\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caFflacULcsJ"
      },
      "source": [
        "## We have created a helper function which includes all those small functions we worked in previous modules.\n",
        "\n",
        "### We can import the functions form the helper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzeJdPiZJxsJ",
        "outputId": "7fab7fcc-6cbf-4fc5-e8c3-114ea9719e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper.py exists already, hence skipping downloading..\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  if os.path.exists(os.path.join(os.getcwd(),\"Helper.py\")):\n",
        "    print(\"helper.py exists already, hence skipping downloading..\")\n",
        "  else:\n",
        "    !wget https://raw.githubusercontent.com/iamatul1214/Tensorflow_Certification_Preparation/main/Helper.py\n",
        "    print(\"Downloaded helper.py successfully\")\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YyQyGXvDMlHe"
      },
      "outputs": [],
      "source": [
        "from Helper import create_tensorboard_callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czXEGN1GarSE"
      },
      "source": [
        "## Let's get some data\n",
        "\n",
        "### This time we will see how we can use the pretrained models frmo `tf.keras.applications` and apply them to our own problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tXGmn2igA_8",
        "outputId": "b7533f73-844f-4dac-cc95-3f49a6f52b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data set is already unzipped and present\n"
          ]
        }
      ],
      "source": [
        "## Getting 10% data of of 10 classes of food\n",
        "from Helper import unzip_data\n",
        "try:\n",
        "  if os.path.exists(os.path.join(os.getcwd(),\"10_food_classes_10_percent.zip\")):\n",
        "    print(f\"data set is already unzipped and present\")\n",
        "  else:\n",
        "    print(\"Downloading the data and unzipping it...\")\n",
        "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "    ### unzipping data\n",
        "    print(\"Unzipping the data\")\n",
        "    unzip_data(\"10_food_classes_10_percent.zip\")\n",
        "\n",
        "\n",
        "    \n",
        "except Exception as e:\n",
        "  print(\"data not found in the directory... Hence downloading.....\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mC9sX55zeyPk"
      },
      "outputs": [],
      "source": [
        "## creating train and test directories\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgWRCBYQdZLx",
        "outputId": "fcba00dd-f353-4c2c-d23d-323b6b6f6a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n"
          ]
        }
      ],
      "source": [
        "## Let's walkthrough the data\n",
        "from Helper import walk_through_dir\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkaaKep2jBRA",
        "outputId": "34a8d0b1-3955-4e1f-d5bd-d4b10ccb8fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "## This time we will not use the ImageDataGenerator, we will use even a smarter version of that.\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory = train_dir,\n",
        "                                                                            image_size = IMG_SIZE,\n",
        "                                                                            label_mode = \"categorical\",\n",
        "                                                                            batch_size = BATCH_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory = test_dir,\n",
        "                                                                image_size = IMG_SIZE,\n",
        "                                                                label_mode = \"categorical\",\n",
        "                                                                batch_size = BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWCedF_moack",
        "outputId": "1148d444-764f-4f06-cfa1-2ea1066d4ba8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data_10_percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYN1d-u9o29D",
        "outputId": "8a640c93-7f79-4caa-f094-b810c4ce044a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_data_10_percent.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97YRzUVcrDf7",
        "outputId": "c5a57e12-c96d-43f9-ded1-c8df45878357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images = [[[[5.42295914e+01 6.22959185e+00 2.22959185e+00]\n",
            "   [5.80714302e+01 9.07142925e+00 5.07142973e+00]\n",
            "   [6.14234695e+01 1.04234686e+01 7.42346811e+00]\n",
            "   ...\n",
            "   [4.80919380e+01 8.09193611e+00 6.09193611e+00]\n",
            "   [5.61325989e+01 1.51325989e+01 1.31325989e+01]\n",
            "   [4.86122360e+01 7.61223412e+00 5.61223412e+00]]\n",
            "\n",
            "  [[5.87857132e+01 9.78571415e+00 5.78571415e+00]\n",
            "   [6.24387779e+01 1.34387779e+01 9.43877792e+00]\n",
            "   [6.16836739e+01 1.06836739e+01 7.68367386e+00]\n",
            "   ...\n",
            "   [4.71377220e+01 6.35198450e+00 4.36728859e+00]\n",
            "   [4.69847527e+01 5.98475456e+00 3.98475432e+00]\n",
            "   [5.91838760e+01 1.81838741e+01 1.61838741e+01]]\n",
            "\n",
            "  [[5.80357132e+01 8.60714340e+00 3.82142901e+00]\n",
            "   [6.15765305e+01 1.05765305e+01 6.57653046e+00]\n",
            "   [5.51479607e+01 3.38265324e+00 3.36734861e-01]\n",
            "   ...\n",
            "   [4.70253830e+01 6.36208439e+00 2.10190678e+00]\n",
            "   [5.01122513e+01 9.11225319e+00 5.11225319e+00]\n",
            "   [4.98928757e+01 8.89287567e+00 4.89287615e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.49357147e+02 2.41142883e+02 2.27714355e+02]\n",
            "   [2.48214264e+02 2.40785736e+02 2.25000000e+02]\n",
            "   [2.47999954e+02 2.38357162e+02 2.22806152e+02]\n",
            "   ...\n",
            "   [2.46382614e+02 2.55000000e+02 2.54571472e+02]\n",
            "   [2.46214264e+02 2.55000000e+02 2.54571472e+02]\n",
            "   [2.46000000e+02 2.55000000e+02 2.54571472e+02]]\n",
            "\n",
            "  [[2.45500031e+02 2.39500031e+02 2.26306168e+02]\n",
            "   [2.46005112e+02 2.40005112e+02 2.26005112e+02]\n",
            "   [2.46770416e+02 2.40770416e+02 2.24770416e+02]\n",
            "   ...\n",
            "   [2.44357147e+02 2.54071442e+02 2.53142883e+02]\n",
            "   [2.44142883e+02 2.54071442e+02 2.53142883e+02]\n",
            "   [2.44142883e+02 2.54071442e+02 2.53142883e+02]]\n",
            "\n",
            "  [[2.45285645e+02 2.41285645e+02 2.29285645e+02]\n",
            "   [2.46903061e+02 2.43903061e+02 2.28903061e+02]\n",
            "   [2.47719498e+02 2.44719498e+02 2.29290924e+02]\n",
            "   ...\n",
            "   [2.45285645e+02 2.54642822e+02 2.54285645e+02]\n",
            "   [2.45285645e+02 2.54642822e+02 2.54285645e+02]\n",
            "   [2.45285645e+02 2.54642822e+02 2.54285645e+02]]]\n",
            "\n",
            "\n",
            " [[[1.85867348e+01 1.95867348e+01 1.15867348e+01]\n",
            "   [2.02857151e+01 2.12857151e+01 1.32857141e+01]\n",
            "   [2.20765305e+01 2.30765305e+01 1.50765305e+01]\n",
            "   ...\n",
            "   [5.71631050e+01 4.85916328e+01 3.93773689e+01]\n",
            "   [5.68469772e+01 4.65867233e+01 3.66581650e+01]\n",
            "   [6.36021919e+01 4.89133492e+01 3.81429634e+01]]\n",
            "\n",
            "  [[1.99285717e+01 2.09285717e+01 1.29285717e+01]\n",
            "   [1.99285717e+01 2.09285717e+01 1.29285717e+01]\n",
            "   [2.07857151e+01 2.17857151e+01 1.37857141e+01]\n",
            "   ...\n",
            "   [7.09337311e+01 6.23622589e+01 5.31479950e+01]\n",
            "   [5.95816078e+01 4.97244644e+01 3.96530380e+01]\n",
            "   [6.29898491e+01 5.12755661e+01 3.93469925e+01]]\n",
            "\n",
            "  [[1.82142849e+01 1.92142849e+01 1.12142859e+01]\n",
            "   [1.82142849e+01 1.92142849e+01 1.12142859e+01]\n",
            "   [1.72142849e+01 1.82142849e+01 1.02142859e+01]\n",
            "   ...\n",
            "   [5.28775826e+01 4.59898529e+01 3.47551460e+01]\n",
            "   [7.24488907e+01 6.60203247e+01 5.42346077e+01]\n",
            "   [5.77091408e+01 5.12805710e+01 3.94948540e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.01428566e+02 1.02428566e+02 9.64285660e+01]\n",
            "   [1.04642853e+02 1.05642853e+02 9.96428528e+01]\n",
            "   [1.08168358e+02 1.09168358e+02 1.03168358e+02]\n",
            "   ...\n",
            "   [1.10785675e+02 1.15785675e+02 1.09785675e+02]\n",
            "   [1.06372429e+02 1.11372429e+02 1.05372429e+02]\n",
            "   [1.03928467e+02 1.08928467e+02 1.02928467e+02]]\n",
            "\n",
            "  [[9.91173172e+01 1.00117317e+02 9.41173172e+01]\n",
            "   [1.02066292e+02 1.03066292e+02 9.70662918e+01]\n",
            "   [1.06285698e+02 1.07285698e+02 1.01285698e+02]\n",
            "   ...\n",
            "   [1.06627457e+02 1.11627457e+02 1.05627457e+02]\n",
            "   [1.03076515e+02 1.08076515e+02 1.02076515e+02]\n",
            "   [1.02402962e+02 1.07402962e+02 1.01402962e+02]]\n",
            "\n",
            "  [[9.82295990e+01 9.92295990e+01 9.32295990e+01]\n",
            "   [1.01857147e+02 1.02857147e+02 9.68571472e+01]\n",
            "   [1.06214287e+02 1.07214287e+02 1.01214287e+02]\n",
            "   ...\n",
            "   [1.00857117e+02 1.05857117e+02 9.98571167e+01]\n",
            "   [1.02765266e+02 1.07765266e+02 1.01765266e+02]\n",
            "   [9.77142944e+01 1.02714294e+02 9.67142944e+01]]]\n",
            "\n",
            "\n",
            " [[[1.66173477e+01 2.19744892e+01 1.39030609e+01]\n",
            "   [2.00102062e+01 2.50357170e+01 1.86020432e+01]\n",
            "   [1.44540815e+01 1.94540806e+01 1.47397957e+01]\n",
            "   ...\n",
            "   [8.72288895e+01 6.05868416e+01 2.45815735e+01]\n",
            "   [4.67601357e+01 6.35203590e+01 1.91428051e+01]\n",
            "   [4.89133110e+01 6.20254784e+01 2.16122341e+01]]\n",
            "\n",
            "  [[1.98673458e+01 2.90051022e+01 1.16734695e+01]\n",
            "   [1.85051022e+01 2.66428566e+01 1.10816326e+01]\n",
            "   [2.07857132e+01 2.88571415e+01 1.53163252e+01]\n",
            "   ...\n",
            "   [9.55757141e+01 6.00815315e+01 2.42803802e+01]\n",
            "   [5.77651596e+01 6.87754288e+01 2.55713234e+01]\n",
            "   [5.30766411e+01 6.05459862e+01 1.95255833e+01]]\n",
            "\n",
            "  [[2.70816326e+01 4.01428566e+01 1.50765314e+01]\n",
            "   [3.70204086e+01 4.91632652e+01 2.26632671e+01]\n",
            "   [3.46887741e+01 4.68316307e+01 2.04234676e+01]\n",
            "   ...\n",
            "   [1.14045021e+02 6.57495728e+01 2.98872738e+01]\n",
            "   [7.18875427e+01 7.30560303e+01 2.74284668e+01]\n",
            "   [5.60052834e+01 5.89184570e+01 1.65664577e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.43423447e+02 4.54949036e+01 5.85202026e+00]\n",
            "   [1.43000000e+02 4.35000153e+01 6.64284897e+00]\n",
            "   [1.37499985e+02 3.51428757e+01 2.18876839e+00]\n",
            "   ...\n",
            "   [1.70357147e+02 1.84357147e+02 4.57856750e+01]\n",
            "   [1.69658127e+02 1.84658127e+02 4.36581306e+01]\n",
            "   [1.66642822e+02 1.81642822e+02 3.86428223e+01]]\n",
            "\n",
            "  [[1.41693863e+02 4.65969505e+01 2.73977208e+00]\n",
            "   [1.43928589e+02 4.78571930e+01 5.92347097e+00]\n",
            "   [1.40295990e+02 4.19541817e+01 3.22962260e+00]\n",
            "   ...\n",
            "   [1.67127518e+02 1.81127518e+02 4.25560493e+01]\n",
            "   [1.67071381e+02 1.82071381e+02 4.10713806e+01]\n",
            "   [1.66045898e+02 1.81045898e+02 3.80459061e+01]]\n",
            "\n",
            "  [[1.38770416e+02 4.67704239e+01 6.88783944e-01]\n",
            "   [1.44311234e+02 5.19795914e+01 5.97450304e+00]\n",
            "   [1.44704086e+02 4.87806091e+01 6.41326761e+00]\n",
            "   ...\n",
            "   [1.64709152e+02 1.78709152e+02 4.01376801e+01]\n",
            "   [1.62071442e+02 1.77071442e+02 3.60714417e+01]\n",
            "   [1.62301056e+02 1.77301056e+02 3.43010559e+01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[1.58169641e+01 8.81696415e+00 0.00000000e+00]\n",
            "   [1.44508924e+01 7.45089293e+00 0.00000000e+00]\n",
            "   [1.49151783e+01 7.91517878e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [9.60003891e+01 5.58307152e+01 1.96610355e+01]\n",
            "   [9.83112106e+01 5.49585190e+01 1.65076199e+01]\n",
            "   [9.80625458e+01 5.06115837e+01 1.07945995e+01]]\n",
            "\n",
            "  [[1.58169641e+01 8.81696415e+00 0.00000000e+00]\n",
            "   [1.44508924e+01 7.45089293e+00 0.00000000e+00]\n",
            "   [1.49151783e+01 7.91517878e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [9.10684586e+01 4.81797218e+01 1.29446764e+01]\n",
            "   [8.98297577e+01 4.53788605e+01 7.47706699e+00]\n",
            "   [9.57455597e+01 4.82946014e+01 8.47761345e+00]]\n",
            "\n",
            "  [[1.58169641e+01 8.81696415e+00 0.00000000e+00]\n",
            "   [1.44508924e+01 7.45089293e+00 0.00000000e+00]\n",
            "   [1.49151783e+01 7.91517878e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [8.35294037e+01 4.05293999e+01 5.52940178e+00]\n",
            "   [8.76693344e+01 4.42184334e+01 8.31663895e+00]\n",
            "   [8.92133484e+01 4.45714264e+01 6.28759336e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[3.93461800e+00 2.50609016e+00 0.00000000e+00]\n",
            "   [9.80045700e+00 8.37192917e+00 4.15738201e+00]\n",
            "   [1.74714661e+01 1.69581184e+01 8.35552597e+00]\n",
            "   ...\n",
            "   [1.04941566e+02 1.06941566e+02 8.59415665e+01]\n",
            "   [1.03159470e+02 1.05513756e+02 8.45137558e+01]\n",
            "   [1.05738556e+02 1.08524292e+02 8.75242920e+01]]\n",
            "\n",
            "  [[1.37914789e+00 1.96112111e-01 2.58039641e+00]\n",
            "   [2.44387627e+00 9.92983401e-01 1.90020883e+00]\n",
            "   [1.07876146e+00 7.87614584e-02 0.00000000e+00]\n",
            "   ...\n",
            "   [1.06020737e+02 1.09020737e+02 9.00207367e+01]\n",
            "   [1.07882317e+02 1.10882317e+02 9.18823166e+01]\n",
            "   [1.05549042e+02 1.08549042e+02 8.95490417e+01]]\n",
            "\n",
            "  [[1.40330410e+00 7.60481715e-01 8.03723240e+00]\n",
            "   [1.41863894e+00 9.32666183e-01 5.16357517e+00]\n",
            "   [4.11702693e-01 3.81406456e-01 6.41937673e-01]\n",
            "   ...\n",
            "   [1.02472321e+02 1.05472321e+02 8.84723206e+01]\n",
            "   [1.05195847e+02 1.08195847e+02 9.11958466e+01]\n",
            "   [1.06766632e+02 1.09766632e+02 9.27666321e+01]]]\n",
            "\n",
            "\n",
            " [[[1.63887756e+02 1.65887756e+02 1.44887756e+02]\n",
            "   [1.80382660e+02 1.79382660e+02 1.59382660e+02]\n",
            "   [1.59581635e+02 1.62795914e+02 1.45663269e+02]\n",
            "   ...\n",
            "   [1.38356964e+02 1.42928436e+02 1.37275421e+02]\n",
            "   [1.23331627e+02 1.29545959e+02 1.27474510e+02]\n",
            "   [1.20596802e+02 1.30183563e+02 1.29183563e+02]]\n",
            "\n",
            "  [[1.69051025e+02 1.68051025e+02 1.50051025e+02]\n",
            "   [1.82280624e+02 1.81280624e+02 1.61280624e+02]\n",
            "   [1.65816330e+02 1.69030609e+02 1.52658173e+02]\n",
            "   ...\n",
            "   [1.39300888e+02 1.41285599e+02 1.35999908e+02]\n",
            "   [1.17556183e+02 1.21847031e+02 1.20704155e+02]\n",
            "   [1.18361900e+02 1.25571182e+02 1.25168091e+02]]\n",
            "\n",
            "  [[1.63005112e+02 1.61576538e+02 1.43790817e+02]\n",
            "   [1.78515305e+02 1.77484695e+02 1.59500000e+02]\n",
            "   [1.58908157e+02 1.61122452e+02 1.47765305e+02]\n",
            "   ...\n",
            "   [1.40887711e+02 1.41459183e+02 1.36459183e+02]\n",
            "   [1.27321396e+02 1.29479584e+02 1.26576546e+02]\n",
            "   [1.23515221e+02 1.28076508e+02 1.28367294e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[8.90663528e+01 4.30663567e+01 1.90663567e+01]\n",
            "   [8.72703857e+01 4.12703857e+01 1.72703876e+01]\n",
            "   [8.71683273e+01 4.11683273e+01 1.71683273e+01]\n",
            "   ...\n",
            "   [1.65091812e+02 1.03091820e+02 2.60918179e+01]\n",
            "   [1.61775528e+02 9.97755203e+01 2.27755241e+01]\n",
            "   [1.66260300e+02 1.04260292e+02 2.72602921e+01]]\n",
            "\n",
            "  [[8.82142563e+01 4.22142601e+01 1.82142601e+01]\n",
            "   [8.69948959e+01 4.09948959e+01 1.69948978e+01]\n",
            "   [8.90000000e+01 4.30000000e+01 1.90000000e+01]\n",
            "   ...\n",
            "   [1.62489761e+02 1.00489754e+02 2.34897575e+01]\n",
            "   [1.66525421e+02 1.04525429e+02 2.75254288e+01]\n",
            "   [1.64357300e+02 1.02357300e+02 2.53572998e+01]]\n",
            "\n",
            "  [[8.67143555e+01 4.07143555e+01 1.67143555e+01]\n",
            "   [8.86429291e+01 4.26429291e+01 1.86429272e+01]\n",
            "   [9.01428909e+01 4.41428909e+01 2.01428909e+01]\n",
            "   ...\n",
            "   [1.65112228e+02 1.03112228e+02 2.61122284e+01]\n",
            "   [1.59831635e+02 9.78316269e+01 2.08316307e+01]\n",
            "   [1.63831390e+02 1.01831383e+02 2.48313828e+01]]]\n",
            "\n",
            "\n",
            " [[[1.77260208e+02 1.04260208e+02 3.62602043e+01]\n",
            "   [1.78051025e+02 1.04051018e+02 3.90510216e+01]\n",
            "   [1.77448975e+02 1.03448982e+02 3.88775520e+01]\n",
            "   ...\n",
            "   [1.52647934e+02 1.18647926e+02 8.32193985e+01]\n",
            "   [1.48142868e+02 1.13142868e+02 8.11428680e+01]\n",
            "   [1.47714218e+02 1.12714218e+02 8.07142181e+01]]\n",
            "\n",
            "  [[1.83285721e+02 1.10285721e+02 4.22857132e+01]\n",
            "   [1.80785721e+02 1.07785721e+02 3.97857170e+01]\n",
            "   [1.84158173e+02 1.10943871e+02 4.35867348e+01]\n",
            "   ...\n",
            "   [1.64658142e+02 1.30658142e+02 9.52296143e+01]\n",
            "   [1.56367325e+02 1.22367325e+02 8.73673248e+01]\n",
            "   [1.52928497e+02 1.18928505e+02 8.39285049e+01]]\n",
            "\n",
            "  [[1.80290817e+02 1.07290817e+02 3.82908173e+01]\n",
            "   [1.80729599e+02 1.07729591e+02 3.87295952e+01]\n",
            "   [1.82214279e+02 1.09214287e+02 4.03826523e+01]\n",
            "   ...\n",
            "   [1.80096939e+02 1.45882660e+02 1.08668373e+02]\n",
            "   [1.71015289e+02 1.36800995e+02 9.94999619e+01]\n",
            "   [1.68076508e+02 1.33862213e+02 9.62142181e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.41194046e+02 8.56225662e+01 3.88368301e+01]\n",
            "   [1.36826553e+02 8.26581879e+01 3.67143097e+01]\n",
            "   [1.36301102e+02 8.25153656e+01 3.72806396e+01]\n",
            "   ...\n",
            "   [2.14377701e+02 1.91331802e+02 1.60469528e+02]\n",
            "   [2.17744965e+02 1.93173492e+02 1.62173492e+02]\n",
            "   [2.21352036e+02 1.96780563e+02 1.65780563e+02]]\n",
            "\n",
            "  [[1.43545944e+02 8.55459442e+01 3.95459366e+01]\n",
            "   [1.41933670e+02 8.56581421e+01 3.87959061e+01]\n",
            "   [1.42117310e+02 8.57142334e+01 4.05152550e+01]\n",
            "   ...\n",
            "   [2.19612305e+02 1.95040833e+02 1.64040833e+02]\n",
            "   [2.17270462e+02 1.92270462e+02 1.61270462e+02]\n",
            "   [2.20831696e+02 1.96831696e+02 1.62831696e+02]]\n",
            "\n",
            "  [[1.54699127e+02 9.66991348e+01 4.86991310e+01]\n",
            "   [1.46188873e+02 8.81888733e+01 4.21888771e+01]\n",
            "   [1.41566605e+02 8.47910309e+01 3.85002441e+01]\n",
            "   ...\n",
            "   [2.17300995e+02 1.92729523e+02 1.61729523e+02]\n",
            "   [2.22719254e+02 1.98719254e+02 1.64719254e+02]\n",
            "   [2.19326691e+02 1.95326691e+02 1.61326691e+02]]]] and labels = [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "32\n"
          ]
        }
      ],
      "source": [
        "## see an example of batches of our data\n",
        "for images, labels in train_data_10_percent.take(1):  ## 32 is the batch size by default hence the take will take 1 batch\n",
        "  print(f\"Images = {images} and labels = {labels}\")\n",
        "  print(len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTA9oaF1xTtW"
      },
      "source": [
        "## Model 0: Using transfer learning to build a keras functional API\n",
        "### The Sequential API runs our layers in the model in sequential manner but functional API is more flexible and can take multiple inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOc8AvaXrLAw",
        "outputId": "8dbd0322-d531-4031-e934-3ac9ea625cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "The shape of the base model after passing the inputs is (None, 7, 7, 1280)\n",
            "The shape of the model after globalaveragepool is (None, 1280)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
            "                                                                 \n",
            " global_average_pool_2d (Glo  (None, 1280)             0         \n",
            " balAveragePooling2D)                                            \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n",
            "moDEL SUMMARY = None\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
            "                                                                 \n",
            " global_average_pool_2d (Glo  (None, 1280)             0         \n",
            " balAveragePooling2D)                                            \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n",
            "moDEL SUMMARY = None\n",
            "Saving TensorBoard log files to: Transfer_learning/feature_extraction-10_percent/20221005-104055\n",
            "Epoch 1/3\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.8750 - accuracy: 0.4280"
          ]
        }
      ],
      "source": [
        "## Create base model with tf.keras.applications \n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "## Freeze the base model so that the underlying pretrained models are not retrained again\n",
        "base_model.trainable = False\n",
        "\n",
        "## create inputs to our model\n",
        "inputs = tf.keras.layers.Input(shape = (224,224,3), name = \"Input layer\")\n",
        "\n",
        "## If we are using a model like Resnet50V2 we will need to normalize inputs, but not for effiecientNet.\n",
        "# x = tf.keras.experimental.preprocessing.Rescaling(1./255)(inputs).  ## this means passing the inputs as parameter\n",
        "\n",
        "x = base_model(inputs)\n",
        "\n",
        "print(f\"The shape of the base model after passing the inputs is {x.shape}\")\n",
        "\n",
        "## Average pool the output of the base_model input layer\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name = \"global_average_pool_2d\") (x)\n",
        "print(f\"The shape of the model after globalaveragepool is {x.shape}\")\n",
        "\n",
        "## create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "## combine the input and output layers\n",
        "model_0 = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "## Let's check the summary of the model\n",
        "print(f\"moDEL SUMMARY = {model_0.summary()}\")\n",
        "\n",
        "## compiling the model\n",
        "model_0.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "## Let's check the summary of the model\n",
        "print(f\"moDEL SUMMARY = {model_0.summary()}\")\n",
        "\n",
        "## fitting the model\n",
        "from Helper import create_tensorboard_callback\n",
        "history_0 = model_0.fit(train_data_10_percent,epochs = 3,steps_per_epoch=len(train_data_10_percent),validation_data=test_data,\n",
        "                        validation_steps = int(0.25 * len(test_data)),callbacks = [create_tensorboard_callback(dir_name = \"Transfer_learning\",\n",
        "                                                                                                               experiment_name = \"feature_extraction-10_percent\")])\n",
        "\n",
        "\n",
        "## validation_steps = int(0.25 * len(test_data)) will reduce the validation steps to 1/4 and hence reduce training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lqriU0R20BH"
      },
      "outputs": [],
      "source": [
        "## Now let's evaluate on full test dataset\n",
        "model_0.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAXRpicE7K4C"
      },
      "outputs": [],
      "source": [
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFayrdgb7mxw"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVi2N_uT7n42"
      },
      "outputs": [],
      "source": [
        "## lET'S CHECK OUR TRAINING CURVES\n",
        "from Helper import plot_loss_curves\n",
        "plot_loss_curves(history_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the feature vector and understanding the function of GlobalAvgPooling layer.\n",
        "We had a tensor from base model of (None, 7,7,1280) shape and after the globalAvgPooling layer we got (None, 1280). Let's use a similar shape custom tensor and check what actually GlobalAvgPooling layer does."
      ],
      "metadata": {
        "id": "PYlLGq3FwfbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "input_shape = (1,4,4,3)\n",
        "\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"The random input tensor = \\n{input_tensor}\\n\")\n",
        "print(f\"The shape of the input tensor = \\n{input_tensor.shape}\")\n",
        "\n",
        "## let's convert the input_tensor into the globalAvgPool\n",
        "\n",
        "global_avg_pool_output = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"The globalAvgPool output = {global_avg_pool_output}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgfTiXgF8V2Y",
        "outputId": "cfd0ad07-8e82-483d-b514-48d180de4e1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The random input tensor = \n",
            "[[[[ 0.3274685  -0.8426258   0.3194337 ]\n",
            "   [-1.4075519  -2.3880599  -1.0392479 ]\n",
            "   [-0.5573232   0.539707    1.6994323 ]\n",
            "   [ 0.28893656 -1.5066116  -0.26454744]]\n",
            "\n",
            "  [[-0.59722406 -1.9171132  -0.62044144]\n",
            "   [ 0.8504023  -0.40604794 -3.0258412 ]\n",
            "   [ 0.9058464   0.29855987 -0.22561555]\n",
            "   [-0.7616443  -1.891714   -0.9384712 ]]\n",
            "\n",
            "  [[ 0.77852213 -0.47338897  0.97772694]\n",
            "   [ 0.24694404  0.20573747 -0.5256233 ]\n",
            "   [ 0.32410017  0.02545409 -0.10638497]\n",
            "   [-0.6369475   1.1603122   0.2507359 ]]\n",
            "\n",
            "  [[-0.41728497  0.40125778 -1.4145442 ]\n",
            "   [-0.59318566 -1.6617213   0.33567193]\n",
            "   [ 0.10815629  0.2347968  -0.56668764]\n",
            "   [-0.35819843  0.88698626  0.5274477 ]]]]\n",
            "\n",
            "The shape of the input tensor = \n",
            "(1, 4, 4, 3)\n",
            "The globalAvgPool output = [[-0.09368646 -0.45840445 -0.28855976]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## So as far as we understood it is taking the avaergage of the features present in input_tensors, Let's see if same output is returned by reduce_mean\n",
        "tf.reduce_mean(input_tensor=input_tensor, axis = [1,2])"
      ],
      "metadata": {
        "id": "Grp08_-DxxMZ",
        "outputId": "444f6149-33d2-48b9-dd2e-3d1827655e9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.09368646, -0.45840445, -0.28855976]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## We can try the same thing using the MaxPool2d as well.\n",
        "max_pool_output  = tf.keras.layers.MaxPool2D()(input_tensor)\n",
        "print(f\"The max pool output = {max_pool_output}\")\n",
        "print(f\"The shape of max pool output = {max_pool_output.shape}\")"
      ],
      "metadata": {
        "id": "CA1zvbUiySJj",
        "outputId": "e95c4f9b-4e09-4636-b6c4-e4dcef6d5641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max pool output = [[[[ 0.8504023  -0.40604794  0.3194337 ]\n",
            "   [ 0.9058464   0.539707    1.6994323 ]]\n",
            "\n",
            "  [[ 0.77852213  0.40125778  0.97772694]\n",
            "   [ 0.32410017  1.1603122   0.5274477 ]]]]\n",
            "The shape of max pool output = (1, 2, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sFh-9-XTykba"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XIlaiqpgtqqkx348CdOGRemPCCi0k9ru",
      "authorship_tag": "ABX9TyNEkeIJ0Tth9jfnvbC2rCN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}